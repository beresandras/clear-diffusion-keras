{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSRJBo9-lwOX"
      },
      "source": [
        "# Clear Diffusion\n",
        "\n",
        "This jupyter notebook contains a training script for the https://github.com/beresandras/clear-diffusion-keras repository, and is intended to be used in a Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Q2l8ZretUZ"
      },
      "outputs": [],
      "source": [
        "# uncomment on first run\n",
        "# !pip install tensorflow_addons\n",
        "# !git clone https://github.com/beresandras/clear-diffusion-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKsXIajqePwJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "sys.path.insert(0,'/content/clear-diffusion-keras')\n",
        "\n",
        "from dataset import prepare_dataset\n",
        "from architecture import get_augmenter, get_network\n",
        "from model import DiffusionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAXcug3LeU4P"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "\n",
        "# data\n",
        "# some datasets might be unavailable for download at times\n",
        "dataset_name = \"oxford_flowers102\"\n",
        "epochs = {\n",
        "    \"caltech_birds2011\": 40,\n",
        "    \"oxford_flowers102\": 40,\n",
        "    \"celeb_a\": 20,\n",
        "    \"cifar10\": 80,\n",
        "}\n",
        "num_epochs = epochs[dataset_name]\n",
        "uncropped_image_size = 64\n",
        "image_size = 64\n",
        "kid_image_size = 75  # resolution of KID measurement (75/150/299)\n",
        "kid_diffusion_steps = 5\n",
        "\n",
        "# optimization\n",
        "prediction_type = \"noise\"\n",
        "loss_type = \"noise\"\n",
        "batch_size = 64\n",
        "ema = 0.999\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# sampling\n",
        "schedule_type = \"cosine\"\n",
        "start_log_snr = 2.5\n",
        "end_log_snr = -7.5\n",
        "\n",
        "# architecture\n",
        "noise_embedding_max_frequency = 200.0\n",
        "noise_embedding_dims = 32\n",
        "image_embedding_dims = 64\n",
        "widths = [32, 64, 96, 128]\n",
        "block_depth = 2\n",
        "\n",
        "id = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKX-vD2jeVLe"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "train_dataset = prepare_dataset(dataset_name, \"train\", uncropped_image_size, batch_size)\n",
        "val_dataset = prepare_dataset(\n",
        "    dataset_name, \"validation\", uncropped_image_size, batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3NnbOlWeVXN"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "model = DiffusionModel(\n",
        "    id=id,\n",
        "    augmenter=get_augmenter(\n",
        "        uncropped_image_size=uncropped_image_size, image_size=image_size\n",
        "    ),\n",
        "    network=get_network(\n",
        "        image_size=image_size,\n",
        "        noise_embedding_max_frequency=noise_embedding_max_frequency,\n",
        "        noise_embedding_dims=noise_embedding_dims,\n",
        "        image_embedding_dims=image_embedding_dims,\n",
        "        widths=widths,\n",
        "        block_depth=block_depth,\n",
        "    ),\n",
        "    prediction_type=prediction_type,\n",
        "    loss_type=loss_type,\n",
        "    batch_size=batch_size,\n",
        "    ema=ema,\n",
        "    schedule_type=schedule_type,\n",
        "    start_log_snr=start_log_snr,\n",
        "    end_log_snr=end_log_snr,\n",
        "    kid_image_size=kid_image_size,\n",
        "    kid_diffusion_steps=kid_diffusion_steps,\n",
        "    is_jupyter=True,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss=keras.losses.mean_absolute_error,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCBVd6DBeViQ"
      },
      "outputs": [],
      "source": [
        "# checkpointing\n",
        "checkpoint_path = \"checkpoints/model_{}\".format(id)\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_kid\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# run training\n",
        "model.augmenter.layers[0].adapt(train_dataset)\n",
        "model.plot_images(epoch=0)\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[\n",
        "        keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
        "        checkpoint_callback,\n",
        "    ],\n",
        ")\n",
        "\n",
        "# load best model\n",
        "model.load_weights(checkpoint_path)\n",
        "# model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DDIM sampling\n",
        "model.plot_images(diffusion_steps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DDIM multistep sampling\n",
        "model.plot_images(diffusion_steps=20, num_multisteps=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DDIM second order sampling\n",
        "model.plot_images(diffusion_steps=20, second_order_alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DDPM variance preserving sampling\n",
        "model.plot_images(diffusion_steps=20, stochasticity=1.0, variance_preserving=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DDPM sampling with large variance\n",
        "model.plot_images(diffusion_steps=200, stochasticity=1.0, variance_preserving=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "clear-diffusion-keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
